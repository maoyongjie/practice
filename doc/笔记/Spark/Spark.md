# Spark

## 一、Spark原理及特点

### 1.1 Spark作业运行流程

![image-20210908185943224](E:\笔记\Spark\image-20210908185943224.png)

#### 1.1.1 Driver

Spark驱动器节点，用于执行Spak任务中的main方法，负责实际代码的执行工作Driver在Spak作业执行时主要负责:

- 将用户程序转化为作业（job）
- 在 Executor之间调度任务（task）
- 跟踪 Executor的执行情况
- 通过U展示查询运行情况

实际上，我们无法准确地描述 Driver的定义，因为在整个的编程过程中没有看到任何有关Driver的字眼。所以简单理解，所谓的 Driver就是驱使整个应用运行起来的程序，也称之为Driver类。

Executor有两个核心功能

- 负责运行组成 Spark应用的任务，并将结果返回给驱动器进程
- 它们通过自身的块管理器（ Block manager）为用户程序中要求缓存的RDD提供内存式存储。RDD是直接缓存在 Executor进程内的，因此任务可以在运行时充分利用缓存数据加速运算。

### 1.2 核心概念

#### 1.2.1 Executor与Core

​	Spark Executor是集群中运行在工作节点（ Worker）中的一个JM进程，是整个集群中的专门用于计算的节点。在提交应用中，可以提供参数指定计算节点的个数，以及对应的资源。这里的资源一般指的是工作节点 Executor的内存大小和使用的虚拟CPU核（Core）数量

## Spark批处理

### Spark批处理架构

![image-20210908190104067](E:\笔记\Spark\image-20210908190104067.png)

### Spark RDD

通俗点来讲，可以将 RDD 理解为一个分布式对象集合，本质上是一个只读的分区记录集合。每个 RDD 可以分成多个分区，每个分区就是一个数据集片段。一个 RDD 的不同分区可以保存到集群中的不同结点上，从而可以在集群中的不同结点上进行并行计算。

### 1.3 提交流程

分为两大块：

**申请资源** 和 **计算准备**

![image-20210908194522872](E:\笔记\Spark\image-20210908194522872.png)

## 三、Spark运行环境

### 3.1 Local模式

idea中为开发环境，非本地环境

### 3.2 Standalone模式

local本地模式毕竟只是用来进行练习演示的，真实工作中还是要将应用提交到对应的集群中去执行。

只使用 Spark自身节点运行的集群模式，也就是所谓的**独立部署（ Standalone）模式** Spark的 Standalone模式体现了经典的 master- slave模式。

![image-20210908192406125](E:\笔记\Spark\image-20210908192406125.png)

### 3.3 Yarn模式

独立部署（ Standalone）模式由spaⅸk自身提供计算资源，无需其他框架提供资源。这种方式降低了和其他第三方资源框架的耦合性，独立性非常强。但是要记住， Spark主要是计算框架，而不是资源调度框架，所以本身提供的资源调度并不是它的强项，所以还是和其他专业的资源调度框架集成会更靠谱一些。所以通常在强大的Yam坏境下工作。

